{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1ckhPhHLwSRbpOZGkcqZLU_fpy09qmZgC","authorship_tag":"ABX9TyOGtRv7OKGXjV0G6U094ast"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ixkxcib00RG4","executionInfo":{"status":"ok","timestamp":1742277371518,"user_tz":-540,"elapsed":4,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"outputs":[],"source":["# GPT 모델을 활용해 다양한 태스크에 Few-shot 학습을 적용할 수 있고, fine-tunning을 통해 원하는 방향으로 모델을 학습"]},{"cell_type":"markdown","source":["# 모델 불러오기"],"metadata":{"id":"yQre7S5e0Z8d"}},{"cell_type":"code","source":["!pip install transformers\n","!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n","!apt-get install git-lfs\n","!git lfs install\n","!git clone https://huggingface.co/taeminlee/kogpt2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EKRjboXk0Wmq","executionInfo":{"status":"ok","timestamp":1742277421874,"user_tz":-540,"elapsed":49752,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"8919483c-8839-4d9c-a594-4e5698c96744"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Detected operating system as Ubuntu/jammy.\n","Checking for curl...\n","Detected curl...\n","Checking for gpg...\n","Detected gpg...\n","Detected apt version as 2.4.13\n","Running apt-get update... done.\n","Installing apt-transport-https... done.\n","Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n","Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n","done.\n","Running apt-get update... done.\n","\n","The repository is setup! You can now install packages.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following packages will be upgraded:\n","  git-lfs\n","1 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n","Need to get 8,489 kB of archives.\n","After this operation, 7,671 kB of additional disk space will be used.\n","Get:1 https://packagecloud.io/github/git-lfs/ubuntu jammy/main amd64 git-lfs amd64 3.6.1 [8,489 kB]\n","Fetched 8,489 kB in 1s (9,769 kB/s)\n","(Reading database ... 125048 files and directories currently installed.)\n","Preparing to unpack .../git-lfs_3.6.1_amd64.deb ...\n","Unpacking git-lfs (3.6.1) over (3.0.2-1ubuntu0.3) ...\n","Setting up git-lfs (3.6.1) ...\n","Git LFS initialized.\n","Processing triggers for man-db (2.10.2-1) ...\n","Git LFS initialized.\n","Cloning into 'kogpt2'...\n","remote: Enumerating objects: 56, done.\u001b[K\n","remote: Total 56 (delta 0), reused 0 (delta 0), pack-reused 56 (from 1)\u001b[K\n","Unpacking objects: 100% (56/56), 1.53 MiB | 4.08 MiB/s, done.\n","Filtering content: 100% (3/3), 1.41 GiB | 67.41 MiB/s, done.\n"]}]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OuFTvN_0dUY","executionInfo":{"status":"ok","timestamp":1742277424887,"user_tz":-540,"elapsed":2999,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"a8e92f78-17b5-464f-b914-6a04365e5987"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"]}]},{"cell_type":"code","source":["import torch\n","from tokenizers import SentencePieceBPETokenizer\n","from transformers import GPT2Config, GPT2LMHeadModel\n","\n","tokenizer = SentencePieceBPETokenizer(\"/content/kogpt2/vocab.json\", \"/content/kogpt2/merges.txt\")\n","\n","config = GPT2Config(vocab_size=50000)\n","config.pad_token_id = tokenizer.token_to_id('<pad>')\n","model = GPT2LMHeadModel(config)\n","\n","model_dir = '/content/kogpt2/pytorch_model.bin'\n","\n","model.load_state_dict(torch.load(model_dir, map_location='cuda'), strict=False)\n","model.to('cuda')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8pBomeJM0bN5","executionInfo":{"status":"ok","timestamp":1742277546815,"user_tz":-540,"elapsed":22899,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"a0a8adb9-3d1f-4481-f045-beb0b84c584c"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50000, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D(nf=2304, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=768)\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D(nf=3072, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=3072)\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50000, bias=False)\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["tokenized_text =  tokenizer.encode('이순신은 조선 중기의 무신이다.', add_special_tokens=True)\n","print(tokenized_text)\n","print(tokenized_text.tokens)\n","print(tokenized_text.ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Vg3J42I1Tkx","executionInfo":{"status":"ok","timestamp":1742277631943,"user_tz":-540,"elapsed":11,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"5666f204-a971-4e2a-f056-08f6d58b7872"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Encoding(num_tokens=7, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","['▁이순', '신은', '▁조선', '▁중기의', '▁무신', '이다', '.']\n","[10925, 6647, 1117, 40249, 39793, 128, 47440]\n"]}]},{"cell_type":"code","source":["tokenizer.add_special_tokens(['<s>','<\\s'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-Mxc90i1tUh","executionInfo":{"status":"ok","timestamp":1742277669251,"user_tz":-540,"elapsed":6,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"acbb3f4e-7586-4701-a101-7ce39eefc3f4"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import torch\n","torch.manual_seed(810)\n","\n","input_ids = torch.tensor(tokenizer.encode('이순신은',add_special_tokens=True).ids).unsqueeze(0).to('cuda')\n","output_sequences = model.generate(input_ids=input_ids,\n","                                  do_sample=True,\n","                                  max_length=100,\n","                                  num_return_sequences=3)\n","for generated_sequence in output_sequences:\n","  generated_sequence = generated_sequence.tolist()\n","  print('generated_sequences : {0}'.format(tokenizer.decode(generated_sequence,skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ciHKoAFU13Dw","executionInfo":{"status":"ok","timestamp":1742278123870,"user_tz":-540,"elapsed":2348,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"ef7af498-a93c-4747-b556-0c088cef8c90"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["generated_sequences : 이순신은 이제껏 자신이 해왔던 삶도 다시 한번 돌아보게 된 상황이다.</s> 최수현 금감원장 역시 5월 2일 오후 3시 명동 은행회관에서 ‘2013년 전국 금융·경제현황 및 하반기 감독방향’을 발표했다.</s> 최 원장은 \"저금리·저성장·저비용 구조로의 전환, 경기회복 지연 등 대내외 리스크와 더불어 가계부채 등 위험 관리강화도 과제\"라고 지적했다.</s> 최 원장은 \"하반기에는 저성장·저금리 기조하에서 서민부담 완화를 위한 보험상품\n","generated_sequences : 이순신은 자신이 왜 그런 짓을 해야 되는지 어떻게 생각했을까?”</s> 이 회장은 2008년 ‘박근혜 정부’ 출범 전인 박대통령 취임 당시 전국경제인연합회장 자격으로 한 강연에 참석했고 같은 해에도 1시간30분 동안 한 강연에서 “박근혜 대통령이 경제를 살리는데 중요한 역할을 하고 있다”고 평가한 바 있다.</s> 이 회장은 박 대통령을 ‘경제 검찰단’이라는 별명을 갖게 한 장본인이자, 재벌 오너가로는 처음 국회의원에 당선된 그를, 왜 국회 청문회만 통과하면 ‘기업\n","generated_sequences : 이순신은 “우리 가족한테 미안한 게 많다”며 오열했다.</s> ‘마마도’ 멤버들을 비롯, 오지호, 김용림, 이성재, 김수미, 손나은, 김용림 등 젊은 여배우들이 함께 등장하며 ‘마마도’는 이날 방송 최초로 새 시트콤을 선보인다.</s> ‘마마도’는 ‘꽃보다 할배’가 이미 지난달 22일 선보인 프로그램들 중 최고 시청률이다.</s> 이미 지난달 방송에 출연했던\n"]}]},{"cell_type":"code","source":["# 토크나이저를 활용해 토큰화\n","# sampling 기법을 활용해 토큰들을 선택하고, 문장을 생성\n","# top-k와 top-p를 각각 50, 0.95로 설정\n","# 반환하는 문장은 1개로 설정 (num_return_sequences)\n","# 문장의 끝을 알리는 스페셜 토큰을 설정 (eos_token_id)\n","# 동일한 토큰이 2회이상 반복되지 못하게 설정 (no_repeat_ngram_size)\n","# 생성 전략을 위와 같이 설정하고, 생성된 문장을 반환하는 함수\n","\n","def get_gpt_output(input_sent):\n","    input_ids = torch.tensor(tokenizer.encode(input_sent, add_special_tokens=True).ids).unsqueeze(0).to('cuda')\n","    sample_outputs = model.generate(\n","        input_ids,\n","        do_sample=True,\n","        max_length=512,\n","        top_k=50,\n","        top_p=0.95,\n","        num_return_sequences=1,\n","        eos_token_id=tokenizer.token_to_id(\"</s>\"),\n","        no_repeat_ngram_size=2,\n","        early_stopping=True\n","    )\n","    generated_sequence = sample_outputs[0].tolist()\n","    return tokenizer.decode(generated_sequence, skip_special_tokens=True)"],"metadata":{"id":"mQGpST-o3E0J","executionInfo":{"status":"ok","timestamp":1742278145966,"user_tz":-540,"elapsed":4,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["get_gpt_output(\"<s>이순신은\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"YhB_t4Ug3rcI","executionInfo":{"status":"ok","timestamp":1742278221595,"user_tz":-540,"elapsed":258,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"8e4ef69a-d662-4abd-aefe-36fca0ef730c"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'이순신은 \"내 딸에게 그 일을 해보자\"면서 이순신을 향해 냅다 뛰쳐나갔다.</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["get_gpt_output(\"<s>철수 : 영희야 안녕!</s><s>영희 : \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"sKyvEX-532gS","executionInfo":{"status":"ok","timestamp":1742278222473,"user_tz":-540,"elapsed":189,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"0ebf72e7-f054-45e8-e698-9a82e79d5270"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'철수 : 영희야 안녕!</s> 영희 : , 벅스칼의 아이린, 너, 우리 집.</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["get_gpt_output(\"<s>본문 : 아.. 기분 진짜 짜증나네ㅡㅡ</s><s>감정 : 분노</s><s>본문 : 와!! 진짜 너무 좋아!!</s><s>감정 : \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"l6qvYhQH38Iw","executionInfo":{"status":"ok","timestamp":1742278266394,"user_tz":-540,"elapsed":73,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"c57af3b9-5635-4023-80ba-b95da95eae33"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'본문 : 아.. 기분 진짜 짜증나네</s> 감정 : 분노</s> 본문 : 와!! 진짜 너무 좋아!!</s> 감정 : ^^* 나..</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["get_gpt_output(\"<s>철수 : 영희야 안녕!</s><s>영희 : 어! 철수야! 오랜만이다!</s><s>철수 : 그러게~ 잘 지냈어?</s><s>영희 : \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Gwe48NKV4Fbo","executionInfo":{"status":"ok","timestamp":1742278312481,"user_tz":-540,"elapsed":248,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"302e49bc-4a9a-402b-bf33-7f1ae48fd1db"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'철수 : 영희야 안녕!</s> 영희 : 어! 철수야! 오랜만이다!</s> 철수 : 그러게~ 잘 지냈어?</s> 영희 : ^^; 영희가 너에 대한 마음 잘 알고 있고 이해해 줬음 좋겠어...</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["# 질의응답 태스크\n","get_gpt_output(\"<s>질문 : 코로나 바이러스에 걸리면 어떻게 되나요?</s>\\\n","<s>답 : COVID-19 환자는 일반적으로 감염 후 평균 5 ~ 6 일 (평균 잠복기 5 ~ 6 일, 범위 1 ~ 14 일)에 경미한 호흡기 증상 및 발열을 포함한 징후와 증상을 나타냅니다. COVID-19 바이러스에 감염된 대부분의 사람들은 경미한 질병을 앓고 회복됩니다.</s>\\\n","<s>질문 : 코로나 바이러스 질병의 첫 증상은 무엇입니까?</s>\\\n","<s>답 : 이 바이러스는 경미한 질병에서 폐렴에 이르기까지 다양한 증상을 유발할 수 있습니다. 질병의 증상은 발열, 기침, 인후통 및 두통입니다. 심한 경우 호흡 곤란과 사망이 발생할 수 있습니다.</s>\\\n","<s>질문 : 딸기 식물의 수명주기는 무엇입니까?</s>\\\n","<s>답 : 딸기의 생애는 새로운 식물의 설립으로 시작하여 2 ~ 3 년 후 절정에 이르렀다가 절정에 이어 2 ~ 3 년에 노화와 죽음을 향해 진행됩니다. 이상적인 조건에서 딸기 식물은 5-6 년까지 살 수 있습니다.</s>\\\n","<s>질문 : 파이썬 메서드의 self 매개 변수의 목적은 무엇입니까?</s>\\\n","<s>답 : self 매개 변수는 클래스의 현재 인스턴스에 대한 참조이며 클래스에 속한 변수에 액세스하는 데 사용됩니다.</s>\\\n","<s>질문 : 뇌의 어떤 부분이 말을 제어합니까?</s>\\\n","<s>답 : 언어 우세 반구의 왼쪽 전두엽 (브로카 영역)에있는 뇌의 분리 된 부분에 대한 손상은 자발적 언어 및 운동 언어 제어 사용에 상당한 영향을 미치는 것으로 나타났습니다.</s>\\\n","<s>질문 : 인공지능의 미래에 대해 어떻게 생각하십니까?</s>\\\n","<s>답 : \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":127},"id":"Kx3Q4C1K4L_x","executionInfo":{"status":"ok","timestamp":1742278405745,"user_tz":-540,"elapsed":372,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"745da6c7-5644-47ce-e650-aa1f8c3556b5"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'질문 : 코로나 바이러스에 걸리면 어떻게 되나요?</s> 답 : COVID-19 환자는 일반적으로 감염 후 평균 5 ~ 6 일 (평균 잠복기 5 ~ 6 일, 범위 1 ~ 14 일)에 경미한 호흡기 증상 및 발열을 포함한 징후와 증상을 나타냅니다. COVID-19 바이러스에 감염된 대부분의 사람들은 경미한 질병을 앓고 회복됩니다.</s> 질문 : 코로나 바이러스 질병의 첫 증상은 무엇입니까?</s> 답 : 이 바이러스는 경미한 질병에서 폐렴에 이르기까지 다양한 증상을 유발할 수 있습니다. 질병의 증상은 발열, 기침, 인후통 및 두통입니다. 심한 경우 호흡 곤란과 사망이 발생할 수 있습니다.</s> 질문 : 딸기 식물의 수명주기는 무엇입니까?</s> 답 : 딸기의 생애는 새로운 식물의 설립으로 시작하여 2 ~ 3 년 후 절정에 이르렀다가 절정에 이어 2 ~ 3 년에 노화와 죽음을 향해 진행됩니다. 이상적인 조건에서 딸기 식물은 5-6 년까지 살 수 있습니다.</s> 질문 : 파이썬 메서드의 self 매개 변수의 목적은 무엇입니까?</s> 답 : self 매개 변수는 클래스의 현재 인스턴스에 대한 참조이며 클래스에 속한 변수에 액세스하는 데 사용됩니다.</s> 질문 : 뇌의 어떤 부분이 말을 제어합니까?</s> 답 : 언어 우세 반구의 왼쪽 전두엽 (브로카 영역)에있는 뇌의 분리 된 부분에 대한 손상은 자발적 언어 및 운동 언어 제어 사용에 상당한 영향을 미치는 것으로 나타났습니다.</s> 질문 : 인공지능의 미래에 대해 어떻게 생각하십니까?</s> 답 : └ (R, B, A) 인공지능 기술은 다양한 인간을 기계화하고 인간의 지능에 대한 통제와 통제 장치를 제공하고 있습니다</l></s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["# 번역 태스킹\n","get_gpt_output(\"<s>한국어: 그 도로는 강과 평행으로 뻗어 있다.</s>\\\n","<s>English: The road runs parallel to the river.</s>\\\n","<s>한국어: 그 평행선들은 분기하는 것처럼 보인다.</s>\\\n","<s>English: The parallel lines appear to diverge.</s>\\\n","<s>한국어: 그 도로와 운하는 서로 평행하다.</s>\\\n","<s>English: The road and the canal are parallel to each other.</s>\\\n","<s>한국어: 평행한 은하계라는 개념은 이해하기가 힘들다.</s>\\\n","<s>English: The idea of a parallel universe is hard to grasp.</s>\\\n","<s>한국어: 이러한 전통은 우리 문화에서는 그에 상응하는 것이 없다.</s>\\\n","<s>English: This tradition has no parallel in our culture.</s>\\\n","<s>한국어: 이것은 현대에 들어서는 그 유례를 찾기 힘든 업적이다.</s>\\\n","<s>English: This is an achievement without parallel in modern times.</s>\\\n","<s>한국어: 그들의 경험과 우리 경험 사이에서 유사점을 찾는 것이 가능하다.</s>\\\n","<s>English: It is possible to draw a parallel between their experience and ours.</s>\\\n","<s>한국어: 그 새 학위 과정과 기존의 수료 과정이 동시에 운영될 수도 있을 것이다.</s>\\\n","<s>English: The new degree and the existing certificate courses would run in parallel.</s>\\\n","<s>한국어: 이순신은 조선 중기의 무신이다.</s>\\\n","<s>Englisth: \")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"id":"dVHkadIC4Xeg","executionInfo":{"status":"ok","timestamp":1742278477939,"user_tz":-540,"elapsed":290,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"39ec68df-64a5-4b3a-fa75-a6da2ae666a3"},"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'한국어: 그 도로는 강과 평행으로 뻗어 있다.</s> English: The road runs parallel to the river.</s> 한국어: 그 평행선들은 분기하는 것처럼 보인다.</s> English: The parallel lines appear to diverge.</s> 한국어: 그 도로와 운하는 서로 평행하다.</s> English: The road and the canal are parallel to each other.</s> 한국어: 평행한 은하계라는 개념은 이해하기가 힘들다.</s> English: The idea of a parallel universe is hard to grasp.</s> 한국어: 이러한 전통은 우리 문화에서는 그에 상응하는 것이 없다.</s> English: This tradition has no parallel in our culture.</s> 한국어: 이것은 현대에 들어서는 그 유례를 찾기 힘든 업적이다.</s> English: This is an achievement without parallel in modern times.</s> 한국어: 그들의 경험과 우리 경험 사이에서 유사점을 찾는 것이 가능하다.</s> English: It is possible to draw a parallel between their experience and ours.</s> 한국어: 그 새 학위 과정과 기존의 수료 과정이 동시에 운영될 수도 있을 것이다.</s> English: The new degree and the existing certificate courses would run in parallel.</s> 한국어: 이순신은 조선 중기의 무신이다.</s> Englisth: ^^* Engjust: outraord of the England of Enginstein.</s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["# Fine-tunning"],"metadata":{"id":"G4sMHiSt5AnY"}},{"cell_type":"markdown","source":["# KoGPT-2 기반 챗봇"],"metadata":{"id":"9qCWMbMs51io"}},{"cell_type":"code","source":["!curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n","!apt-get install git-lfs\n","\n","!git lfs install\n","!git clone https://huggingface.co/taeminlee/kogpt2\n","!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zOPBWfrc40FE","executionInfo":{"status":"ok","timestamp":1742278742850,"user_tz":-540,"elapsed":19227,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"edb92927-7792-48c5-ee2e-9c7302a81f42"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Detected operating system as Ubuntu/jammy.\n","Checking for curl...\n","Detected curl...\n","Checking for gpg...\n","Detected gpg...\n","Detected apt version as 2.4.13\n","Running apt-get update... done.\n","Installing apt-transport-https... done.\n","Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n","Importing packagecloud gpg key... Packagecloud gpg key imported to /etc/apt/keyrings/github_git-lfs-archive-keyring.gpg\n","done.\n","Running apt-get update... done.\n","\n","The repository is setup! You can now install packages.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","git-lfs is already the newest version (3.6.1).\n","0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n","Git LFS initialized.\n","fatal: destination path 'kogpt2' already exists and is not an empty directory.\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"]}]},{"cell_type":"code","source":["import torch\n","from tokenizers import SentencePieceBPETokenizer\n","from transformers import GPT2Config, GPT2LMHeadModel\n","\n","tokenizer = SentencePieceBPETokenizer(\"/content/kogpt2/vocab.json\", \"/content/kogpt2/merges.txt\")\n","\n","config = GPT2Config(vocab_size=50000)\n","model = GPT2LMHeadModel(config)\n","\n","model_dir = '/content/kogpt2/pytorch_model.bin'\n","\n","model.load_state_dict(torch.load(model_dir, map_location='cuda'), strict=False)\n","model.to('cuda')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KHE1W_BB5EJI","executionInfo":{"status":"ok","timestamp":1742278752183,"user_tz":-540,"elapsed":9328,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"d800f713-418e-4a57-ce53-d823853d6272"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(50000, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D(nf=2304, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=768)\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D(nf=3072, nx=768)\n","          (c_proj): Conv1D(nf=768, nx=3072)\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=50000, bias=False)\n",")"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["import torch\n","torch.manual_seed(810)\n","\n","input_ids = torch.tensor(tokenizer.encode('이순신은',add_special_tokens=True).ids).unsqueeze(0).to('cuda')\n","output_sequences = model.generate(input_ids=input_ids,\n","                                  do_sample=True,\n","                                  max_length=100,\n","                                  num_return_sequences=3)\n","for generated_sequence in output_sequences:\n","  generated_sequence = generated_sequence.tolist()\n","  print('generated_sequences : {0}'.format(tokenizer.decode(generated_sequence,skip_special_tokens=True)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mWR8SX9T6BS4","executionInfo":{"status":"ok","timestamp":1742278777314,"user_tz":-540,"elapsed":2294,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"7eea1fd9-8491-444c-84d0-f685c92349d4"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"stream","name":"stdout","text":["generated_sequences : 이순신은 이제껏 자신이 해왔던 삶도 다시 한번 돌아보게 된 상황이다.</s><s> 최수현 금감원장 역시 5월 2일 오후 3시 명동 은행회관에서 ‘2013년 전국 금융·경제현황 및 하반기 감독방향’을 발표했다.</s><s> 최 원장은 \"저금리·저성장·저비용 구조로의 전환, 경기회복 지연 등 대내외 리스크와 더불어 가계부채 등 위험 관리강화도 과제\"라고 지적했다.</s><s> 최 원장은 \"하반기에는 저성장·저금리 기조하에서 서민부담 완화를 위한 보험상품\n","generated_sequences : 이순신은 자신이 왜 그런 짓을 해야 되는지 어떻게 생각했을까?”</s><s> 이 회장은 2008년 ‘박근혜 정부’ 출범 전인 박대통령 취임 당시 전국경제인연합회장 자격으로 한 강연에 참석했고 같은 해에도 1시간30분 동안 한 강연에서 “박근혜 대통령이 경제를 살리는데 중요한 역할을 하고 있다”고 평가한 바 있다.</s><s> 이 회장은 박 대통령을 ‘경제 검찰단’이라는 별명을 갖게 한 장본인이자, 재벌 오너가로는 처음 국회의원에 당선된 그를, 왜 국회 청문회만 통과하면 ‘기업\n","generated_sequences : 이순신은 “우리 가족한테 미안한 게 많다”며 오열했다.</s><s> ‘마마도’ 멤버들을 비롯, 오지호, 김용림, 이성재, 김수미, 손나은, 김용림 등 젊은 여배우들이 함께 등장하며 ‘마마도’는 이날 방송 최초로 새 시트콤을 선보인다.</s><s> ‘마마도’는 ‘꽃보다 할배’가 이미 지난달 22일 선보인 프로그램들 중 최고 시청률이다.</s><s> 이미 지난달 방송에 출연했던\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","data = pd.read_csv('/content/drive/MyDrive/1자연어처리/dataset/ChatbotData.csv')\n","\n","data.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"LerDhlr6541g","executionInfo":{"status":"ok","timestamp":1742278795527,"user_tz":-540,"elapsed":1903,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"3c12f956-5638-4903-e909-9d88ccf65805"},"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                         Q                   A  label\n","0                   12시 땡!          하루가 또 가네요.      0\n","1              1지망 학교 떨어졌어           위로해 드립니다.      0\n","2             3박4일 놀러가고 싶다         여행은 언제나 좋죠.      0\n","3          3박4일 정도 놀러가고 싶다         여행은 언제나 좋죠.      0\n","4                  PPL 심하네          눈살이 찌푸려지죠.      0\n","5                SD카드 망가졌어  다시 새로 사는 게 마음 편해요.      0\n","6                  SD카드 안돼  다시 새로 사는 게 마음 편해요.      0\n","7           SNS 맞팔 왜 안하지ㅠㅠ    잘 모르고 있을 수도 있어요.      0\n","8  SNS 시간낭비인 거 아는데 매일 하는 중       시간을 정하고 해보세요.      0\n","9        SNS 시간낭비인데 자꾸 보게됨       시간을 정하고 해보세요.      0"],"text/html":["\n","  <div id=\"df-31d78f41-7ddf-423d-9b90-25bd3a40ea66\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>SD카드 망가졌어</td>\n","      <td>다시 새로 사는 게 마음 편해요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>SD카드 안돼</td>\n","      <td>다시 새로 사는 게 마음 편해요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>SNS 맞팔 왜 안하지ㅠㅠ</td>\n","      <td>잘 모르고 있을 수도 있어요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>SNS 시간낭비인 거 아는데 매일 하는 중</td>\n","      <td>시간을 정하고 해보세요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>SNS 시간낭비인데 자꾸 보게됨</td>\n","      <td>시간을 정하고 해보세요.</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31d78f41-7ddf-423d-9b90-25bd3a40ea66')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-31d78f41-7ddf-423d-9b90-25bd3a40ea66 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-31d78f41-7ddf-423d-9b90-25bd3a40ea66');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-42447f28-0ce1-4025-b4fa-17a412094c47\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-42447f28-0ce1-4025-b4fa-17a412094c47')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-42447f28-0ce1-4025-b4fa-17a412094c47 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"data","summary":"{\n  \"name\": \"data\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11662,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\ud558\\ub294 \\uc0ac\\ub78c \\uc78a\\ub294 \\ubc95\",\n          \"\\uc220 \\uc548 \\uba39\\uc73c\\uba74 \\uce5c\\uad6c\\ub791 \\ubb50\\ud558\\uc9c0\",\n          \"\\uc9dd\\ub0a8\\uc774 \\uace0\\uc2dc\\uc0dd\\uc774\\uba74 \\uae30\\ub2e4\\ub824\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["added_special_token_num = tokenizer.add_special_tokens(['<s>','<\\s>'])\n","print(added_special_token_num)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qFBBupNA64ck","executionInfo":{"status":"ok","timestamp":1742279046769,"user_tz":-540,"elapsed":13,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"4d034602-f70a-4dc6-d685-ac2d84c26bcf"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]}]},{"cell_type":"code","source":["added_special_token_num = tokenizer.add_special_tokens(['<s>', '</s>'])\n","\n","pad_id = tokenizer.token_to_id(\"<pad>\")\n","tokenizer.enable_padding(pad_id=pad_id, pad_token=\"<pad>\")\n","tokenizer.enable_truncation(max_length=128)"],"metadata":{"id":"tfRUTn3Z6Jjx","executionInfo":{"status":"ok","timestamp":1742279049663,"user_tz":-540,"elapsed":1,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["class ChatDataset(torch.utils.data.Dataset):\n","    def __init__(self, tokenizer, file_path):\n","        self.data = []\n","        self.file_path = file_path\n","        self.tokenizer = tokenizer\n","\n","    def load_data(self):\n","        raw_data = pd.read_csv(self.file_path)\n","        train_data = '<s>'+raw_data['Q']+'</s>'+'<s>'+raw_data['A']+'</s>'\n","        #<s>안녕하세요</s><s> -> 네, 안녕하세요</s>\n","        tokenized_train_data = tokenizer.encode_batch(train_data)\n","        for single_data in tokenized_train_data:\n","            self.data.append(torch.tensor(single_data.ids).unsqueeze(0))\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        item = self.data[index]\n","        return item"],"metadata":{"id":"CqadNLKA7IEo","executionInfo":{"status":"ok","timestamp":1742279183425,"user_tz":-540,"elapsed":2,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["train_dataset = ChatDataset(tokenizer=tokenizer, file_path='/content/drive/MyDrive/1자연어처리/dataset/ChatbotData.csv')\n","train_dataset.load_data()"],"metadata":{"id":"QvGz5Udy7oug","executionInfo":{"status":"ok","timestamp":1742279188660,"user_tz":-540,"elapsed":1505,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"execution_count":52,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","\n","data_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"],"metadata":{"id":"tGJQ-_Uj7po7","executionInfo":{"status":"ok","timestamp":1742279298166,"user_tz":-540,"elapsed":37,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"execution_count":53,"outputs":[]},{"cell_type":"code","source":["from transformers import AdamW"],"metadata":{"id":"Pg2-DVLI8Euw","executionInfo":{"status":"ok","timestamp":1742279333808,"user_tz":-540,"elapsed":61,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"execution_count":54,"outputs":[]},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(), lr=1e-4, correct_bias=True)\n","\n","epochs = 3\n","\n","avg_loss = (0.0, 0.0)\n","for epoch in range(epochs):\n","    count=0\n","    for data in data_loader:\n","        optimizer.zero_grad()\n","        data = data.transpose(1,0)\n","        data = data.to('cuda')\n","        model = model.to('cuda')\n","\n","        outputs = model(data, labels=data)\n","        loss, logits = outputs[:2]\n","        loss = loss.to('cuda')\n","        loss.backward()\n","        avg_loss = (avg_loss[0] * 0.99 + loss, avg_loss[1] * 0.99 + 1.0)\n","        optimizer.step()\n","        if count % 200 == 0:\n","            print('epoch no.{0}  train ({1}/{2})  loss = {3:.5f}  avg_loss = {4:.5f}' . format(epoch, count, len(data_loader), loss, avg_loss[0] / avg_loss[1]))\n","        count += 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FEfmjX1m8Naw","executionInfo":{"status":"ok","timestamp":1742280108709,"user_tz":-540,"elapsed":766166,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"c62c3002-6ce7-4dc5-93e7-90c48fb1304b"},"execution_count":55,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"]},{"output_type":"stream","name":"stdout","text":["epoch no.0  train (0/2956)  loss = 2.60043  avg_loss = 2.60043\n","epoch no.0  train (200/2956)  loss = 1.16710  avg_loss = 1.42033\n","epoch no.0  train (400/2956)  loss = 1.56775  avg_loss = 1.28432\n","epoch no.0  train (600/2956)  loss = 1.51741  avg_loss = 1.24869\n","epoch no.0  train (800/2956)  loss = 1.24334  avg_loss = 1.22887\n","epoch no.0  train (1000/2956)  loss = 1.39677  avg_loss = 1.19253\n","epoch no.0  train (1200/2956)  loss = 0.81266  avg_loss = 1.18901\n","epoch no.0  train (1400/2956)  loss = 1.19541  avg_loss = 1.16701\n","epoch no.0  train (1600/2956)  loss = 1.07766  avg_loss = 1.16359\n","epoch no.0  train (1800/2956)  loss = 0.84263  avg_loss = 1.14167\n","epoch no.0  train (2000/2956)  loss = 1.40876  avg_loss = 1.18326\n","epoch no.0  train (2200/2956)  loss = 0.76773  avg_loss = 1.14281\n","epoch no.0  train (2400/2956)  loss = 0.87162  avg_loss = 1.14369\n","epoch no.0  train (2600/2956)  loss = 1.14763  avg_loss = 1.11574\n","epoch no.0  train (2800/2956)  loss = 1.30465  avg_loss = 1.09955\n","epoch no.1  train (0/2956)  loss = 0.74017  avg_loss = 1.09896\n","epoch no.1  train (200/2956)  loss = 0.98500  avg_loss = 0.96555\n","epoch no.1  train (400/2956)  loss = 1.27718  avg_loss = 0.94087\n","epoch no.1  train (600/2956)  loss = 1.12248  avg_loss = 0.95492\n","epoch no.1  train (800/2956)  loss = 1.12551  avg_loss = 0.96162\n","epoch no.1  train (1000/2956)  loss = 1.02430  avg_loss = 0.96053\n","epoch no.1  train (1200/2956)  loss = 0.90160  avg_loss = 0.92900\n","epoch no.1  train (1400/2956)  loss = 0.85262  avg_loss = 0.93755\n","epoch no.1  train (1600/2956)  loss = 1.30134  avg_loss = 0.94688\n","epoch no.1  train (1800/2956)  loss = 0.80320  avg_loss = 0.94378\n","epoch no.1  train (2000/2956)  loss = 0.72245  avg_loss = 0.96169\n","epoch no.1  train (2200/2956)  loss = 0.75537  avg_loss = 0.92201\n","epoch no.1  train (2400/2956)  loss = 0.85168  avg_loss = 0.91521\n","epoch no.1  train (2600/2956)  loss = 1.14842  avg_loss = 0.94074\n","epoch no.1  train (2800/2956)  loss = 1.15615  avg_loss = 0.93866\n","epoch no.2  train (0/2956)  loss = 0.70963  avg_loss = 0.93340\n","epoch no.2  train (200/2956)  loss = 0.72419  avg_loss = 0.78905\n","epoch no.2  train (400/2956)  loss = 0.70485  avg_loss = 0.76871\n","epoch no.2  train (600/2956)  loss = 0.75345  avg_loss = 0.77495\n","epoch no.2  train (800/2956)  loss = 0.84120  avg_loss = 0.75935\n","epoch no.2  train (1000/2956)  loss = 0.69608  avg_loss = 0.76047\n","epoch no.2  train (1200/2956)  loss = 0.77340  avg_loss = 0.78220\n","epoch no.2  train (1400/2956)  loss = 0.62851  avg_loss = 0.77154\n","epoch no.2  train (1600/2956)  loss = 0.81008  avg_loss = 0.77032\n","epoch no.2  train (1800/2956)  loss = 0.88123  avg_loss = 0.77796\n","epoch no.2  train (2000/2956)  loss = 0.62729  avg_loss = 0.78751\n","epoch no.2  train (2200/2956)  loss = 0.81227  avg_loss = 0.77087\n","epoch no.2  train (2400/2956)  loss = 0.57600  avg_loss = 0.78396\n","epoch no.2  train (2600/2956)  loss = 0.95158  avg_loss = 0.78548\n","epoch no.2  train (2800/2956)  loss = 0.84145  avg_loss = 0.78368\n"]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), '/content/drive/MyDrive/1자연어처리/gpt-2_chatbot/chitchat_model.bin')"],"metadata":{"id":"WQwhCK6Y8Pk4","executionInfo":{"status":"ok","timestamp":1742280173796,"user_tz":-540,"elapsed":1866,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["def encoding(text):\n","    text = '<s>'+text+'</s><s>'\n","    return torch.tensor(tokenizer.encode(text).ids).unsqueeze(0).to('cuda')\n","\n","def decoding(ids):\n","    return tokenizer.decode_batch(ids)\n","\n","tokenizer.no_padding()\n","tokenizer.no_truncation()\n","\n","e_s = tokenizer.token_to_id('</s>')\n","unk = tokenizer.token_to_id('<unk>')"],"metadata":{"id":"djo-UQfK_NEp","executionInfo":{"status":"ok","timestamp":1742280188372,"user_tz":-540,"elapsed":46,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"execution_count":59,"outputs":[]},{"cell_type":"code","source":["def get_answer(input_sent):\n","    input_ids = encoding(input_sent)\n","\n","    sample_outputs = model.generate(\n","        input_ids,\n","        num_return_sequences=5,\n","        do_sample=True,\n","        max_length=128,\n","        top_k=50,\n","        top_p=0.95,\n","        eos_token_id=e_s,\n","        early_stopping=True,\n","        bad_words_ids=[[unk]]\n","    )\n","\n","    decoded_result = decoding(sample_outputs.tolist())\n","    for result in decoded_result:\n","        print(result)"],"metadata":{"id":"sb7Wn0Zl_eDX","executionInfo":{"status":"ok","timestamp":1742280203295,"user_tz":-540,"elapsed":2,"user":{"displayName":"손정락","userId":"10892662232752168928"}}},"execution_count":60,"outputs":[]},{"cell_type":"code","source":["get_answer('안녕?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u5Nac8Aq_ht4","executionInfo":{"status":"ok","timestamp":1742280315194,"user_tz":-540,"elapsed":171,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"4495c252-e2af-4a81-bc37-7d47fef41183"},"execution_count":62,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["안녕? 안녕하세요.\n","안녕? 안녕하세요. 반갑습니다.\n","안녕? 안녕!\n","안녕? 안녕.\n","안녕? 안녕하세요.\n"]}]},{"cell_type":"code","source":["get_answer('만나서 반가워.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gH01kD___0S6","executionInfo":{"status":"ok","timestamp":1742280318958,"user_tz":-540,"elapsed":95,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"9de5459f-40f7-4f45-9ff7-799088f09ea7"},"execution_count":63,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["만나서 반가워. 감사합니다.\n","만나서 반가워. 잘하고 오세요.\n","만나서 반가워. 진짜 반가워요.\n","만나서 반가워. 정말 반가웠어요.\n","만나서 반가워. 많이 만나셨군요.\n"]}]},{"cell_type":"code","source":["get_answer('인공지능의 미래에 대해 어떻게 생각하세요?')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BP0X5dZG_97v","executionInfo":{"status":"ok","timestamp":1742280336043,"user_tz":-540,"elapsed":915,"user":{"displayName":"손정락","userId":"10892662232752168928"}},"outputId":"829ecc88-2709-48cd-e047-05c5f6f59418"},"execution_count":64,"outputs":[{"output_type":"stream","name":"stderr","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:1 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["인공지능의 미래에 대해 어떻게 생각하세요? 인공지능은 더 똑똑해 질 거예요.\n","인공지능의 미래에 대해 어떻게 생각하세요? 인공지능은 모든 일을 하고 싶어할 거예요.\n","인공지능의 미래에 대해 어떻게 생각하세요? 인공지능은 정말 무궁무진할 거라 생각해요. 인공지능은 인공지능의 미래가 될 거예요.\n","인공지능의 미래에 대해 어떻게 생각하세요? 인공지능은 미래에 대해 이야기할 수 있을 거예요. 인공지능이 중요하겠지만 인공지능은 중요하지 않아요. 인공지능은 현실을 반영하지 않아요.\n","인공지능의 미래에 대해 어떻게 생각하세요? 인공지능이 가장 먼저 인공지능에 물어보는 게 좋을 것 같아요. 인공지능이 정말 중요할 때가 있어요. 인공지능이 가장 중요한 게 되는 걸 수도 있어요.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"yD4lS5_NAB54"},"execution_count":null,"outputs":[]}]}